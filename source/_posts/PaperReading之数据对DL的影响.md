---
title: PaperReading之数据对DL的影响
notshow: false
tags:
  - data
categories:
  - PaperReading
abbrlink: ad9b8c50
date: 2022-02-07 10:08:03
---

引言：本文主要介绍ICCV2017论文《Revisiting Unreasonable Effectiveness of Data in Deep Learning Era》。

<!--more-->

### 综述

这篇论文主要介绍了作者在数据集大小对深度学习性能的影响，得出了一些结论。

### 结论

结论一：增大数据集有助于提升表征学习的性能，也就是类似于CNN这种自动提取特征的学习受益于数据集的增大，而且数据集的规模可以战胜标签噪声，作者在JFT-300数据集上的实验证明了这一点，虽然数据集的标签中仍然有20%的噪声，但是增大数据集依然获得了预想中的性能提升。

结论二：任务表现与**数据量级**呈线性关系，即与数据量呈对数关系，对于JFT-300这么大的数据量，也没有出现平顶效应。

结论三：模型容量也很重要，在大规模数据量下，模型容量越大，也就是层数越多，收益越大。

结论四：数据量增加会带来更好的结果。

